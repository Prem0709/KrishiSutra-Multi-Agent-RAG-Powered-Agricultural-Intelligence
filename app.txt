import streamlit as st
import yaml
import google.generativeai as genai
import os
import json
from datetime import datetime

from agents.climate_agent import build_climate_agent
from agents.agriculture_agent import build_agriculture_agent
from agents.scheme_agent import build_scheme_agent
from agents.kcc_agent import build_kcc_agent
from utils.api_fetcher import fetch_data_gov_api


# ----------------------------------
# 1Ô∏è‚É£ Load Configurations
# ----------------------------------
def load_config():
    config_path = os.path.join(os.path.dirname(__file__), "config.yaml")
    with open(config_path, "r") as f:
        return yaml.safe_load(f)

config = load_config()

# Read keys and parameters
DATA_GOV_API_KEY = config["data_gov"]["api_key"]
LLM_PROVIDER = config.get("llm_provider", "gemini")
GEMINI_API_KEY = config.get("google_api_key")
EMBEDDING_MODEL = config.get("embedding_model", "models/embedding-001")
EMBEDDING_PROVIDER = config.get("embedding_provider", "huggingface")
CHAT_MODEL = config.get("chat_model", "models/gemini-pro-latest")

# ‚úÖ Configure Gemini API
if LLM_PROVIDER.lower() == "gemini" and GEMINI_API_KEY:
    # Using getattr to avoid linter issues
    configure_func = getattr(genai, 'configure')
    configure_func(api_key=GEMINI_API_KEY)
    st.sidebar.success(f"‚úÖ Gemini Configured ({CHAT_MODEL})")
    st.sidebar.info(f"üìä Embeddings: {EMBEDDING_PROVIDER.upper()}")
else:
    st.sidebar.error("‚ùå Gemini API key missing or provider not set to 'gemini'.")


# ----------------------------------
# 2Ô∏è‚É£ Streamlit UI Setup
# ----------------------------------
st.set_page_config(page_title="üåæ Project Samarth ‚Äî Gemini Multi-RAG", layout="centered")

# Centered title and caption
st.markdown("<h1 style='text-align: center;'>üåæ Project Samarth</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center; font-size: 1.2em;'>krishisutra-ai-powered-agricultural-intelligence</p>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center;'>Powered by Multi-Agent RAG + Gemini</p>", unsafe_allow_html=True)

# Initialize session state for chat history
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

st.sidebar.header("‚öôÔ∏è Configuration")
agent_choice = st.sidebar.selectbox(
    "Select Knowledge Agent:",
    ["Auto Detect", "üå¶Ô∏è Climate Agent", "üåæ Agriculture Agent", "üßæ Scheme Agent", "‚òéÔ∏è KCC Agent"]
)

uploaded_file = st.sidebar.file_uploader(
    "üì§ Upload Custom Dataset (CSV, Excel, JSON, ZIP)",
    type=["csv", "xlsx", "xls", "json", "zip"],
)

if GEMINI_API_KEY:
    st.sidebar.success("‚úÖ Gemini API key loaded")
else:
    st.sidebar.error("‚ùå Missing Gemini API key")


# ----------------------------------
# 3Ô∏è‚É£ Agent Initializer
# ----------------------------------
@st.cache_resource(show_spinner=False)
def get_agent(agent_choice, api_key=None, uploaded_file=None):
    """Dynamically build and return the chosen RAG agent"""
    temp_path = None

    # Save uploaded file for use
    if uploaded_file:
        temp_path = f"data/{uploaded_file.name}"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.read())
        st.sidebar.success(f"‚úÖ Loaded file: {uploaded_file.name}")

    if agent_choice == "üå¶Ô∏è Climate Agent":
        return build_climate_agent(temp_path or "data/Mean_Temp_IMD_2017.csv")

    elif agent_choice == "üåæ Agriculture Agent":
        return build_agriculture_agent(temp_path or "data/Current Daily Price of Various Commodities from Various Markets (Mandi).csv")

    elif agent_choice == "üßæ Scheme Agent":
        return build_scheme_agent(temp_path or "data/GetPMKisanDatagov.json")

    elif agent_choice == "‚òéÔ∏è KCC Agent":
        if api_key:
            return build_kcc_agent(api_key)
        else:
            st.error("‚ùå Missing data.gov.in API key for KCC Agent.")
            return None

    return None


# ----------------------------------
# 4Ô∏è‚É£ Auto Agent Detection
# ----------------------------------
def auto_select_agent(user_query):
    query = user_query.lower()
    if any(word in query for word in ["rain", "temperature", "climate", "weather"]):
        return "üå¶Ô∏è Climate Agent"
    elif any(word in query for word in ["crop", "yield", "price", "production", "agriculture"]):
        return "üåæ Agriculture Agent"
    elif any(word in query for word in ["scheme", "pmkisan", "subsidy", "beneficiary"]):
        return "üßæ Scheme Agent"
    elif any(word in query for word in ["kcc", "helpline", "call centre"]):
        return "‚òéÔ∏è KCC Agent"
    else:
        return None


# ----------------------------------
# 5Ô∏è‚É£ Gemini Response Helper
# ----------------------------------
def gemini_answer(prompt, context=""):
    """Uses Gemini 1.5 model to generate a clean, factual answer"""
    try:
        # Use the configured model from config.yaml (CHAT_MODEL). Example: 'models/gemini-pro-latest'
        # Using getattr to avoid linter issues
        GenerativeModelClass = getattr(genai, 'GenerativeModel')
        model = GenerativeModelClass(CHAT_MODEL)
        full_prompt = f"""
        You are an AI assistant for smart agriculture.
        Use the following context to answer the question accurately.

        Context:
        {context}

        Question:
        {prompt}

        Provide a concise, factual, and human-readable answer.
        """
        response = model.generate_content(full_prompt)
        return response.text or "‚ö†Ô∏è No response generated."
    except Exception as e:
        return f"‚ùå Error: {str(e)}"


# ----------------------------------
# 6Ô∏è‚É£ Chat Interface
# ----------------------------------
st.markdown("## üí¨ Chat with Samarth AI")
user_query = st.text_input("Ask your question (e.g., 'Compare rainfall and rice yield in Maharashtra')")

if st.button("Submit") and user_query:
    with st.spinner("üîé Analyzing and fetching data..."):
        # Step 1: Auto-select agent
        selected_agent = agent_choice
        if agent_choice == "Auto Detect":
            selected_agent = auto_select_agent(user_query)

        if not selected_agent:
            st.warning("ü§ñ Could not auto-detect domain. Please select an agent manually.")
            st.stop()

        # Step 2: Initialize selected agent
        qa_agent = get_agent(selected_agent, DATA_GOV_API_KEY, uploaded_file)

        if not qa_agent:
            st.error("‚ùå Failed to initialize selected agent.")
            st.stop()

        # Step 3: Retrieve domain-specific context
        try:
            context = qa_agent.retrieve_context(user_query)
        except AttributeError:
            # Fallback: if old `.run()` method exists
            context = qa_agent.run(user_query)

        # Step 4: Use Gemini to generate final answer
        final_answer = gemini_answer(user_query, context)
        
        # Store in chat history
        st.session_state.chat_history.append({
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "query": user_query,
            "agent": selected_agent,
            "answer": final_answer
        })
        
        st.success("‚úÖ Response:")
        st.write(final_answer)

# History section
st.markdown("## üìú Query History")
if st.session_state.chat_history:
    # Show history in reverse chronological order (newest first)
    for i, chat in enumerate(reversed(st.session_state.chat_history)):
        with st.expander(f"{chat['timestamp']} - {chat['query'][:50]}{'...' if len(chat['query']) > 50 else ''}"):
            st.markdown(f"**Query:** {chat['query']}")
            st.markdown(f"**Agent:** {chat['agent']}")
            st.markdown(f"**Response:** {chat['answer']}")
else:
    st.info("No history yet. Start asking questions to see your query history here.")

# ----------------------------------
# 7Ô∏è‚É£ Footer
# ----------------------------------
st.sidebar.markdown("---")
st.sidebar.caption("üë®‚Äçüíª Developed by Premkumar Pawar | Multi-Agent RAG with Gemini")
