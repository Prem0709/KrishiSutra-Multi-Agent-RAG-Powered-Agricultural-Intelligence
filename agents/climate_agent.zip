from utils.data_loader import load_data
# from langchain.embeddings import OpenAIEmbeddings
from langchain_openai import OpenAIEmbeddings
# from langchain.vectorstores import FAISS
from langchain_community.vectorstores import FAISS

# from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_text_splitters import RecursiveCharacterTextSplitter

# from langchain.chains import RetrievalQA
from langchain_classic.chains import RetrievalQA

# from langchain.chat_models import ChatOpenAI
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
# from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain.vectorstores import FAISS
# from langchain.chains import RetrievalQA
from langchain_core.documents import Document

import pandas as pd
import json, os, yaml

def build_climate_agent(config):
    api_key = config.get("google_api_key")
    os.environ["GOOGLE_API_KEY"] = api_key

    # Load data
    df = pd.read_csv("data/Mean_Temp_IMD_2017.csv")
    docs = [Document(page_content=row.to_string()) for _, row in df.iterrows()]

    # Split & Embed
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = text_splitter.split_documents(docs)
    
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vectorstore = FAISS.from_documents(chunks, embeddings)
    retriever = vectorstore.as_retriever()

    # Gemini model for reasoning
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro", temperature=0.3)

    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        return_source_documents=True
    )

    return qa_chain
